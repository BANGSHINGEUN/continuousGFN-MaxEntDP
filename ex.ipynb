{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5240a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import argparse\n",
    "\n",
    "from env import Box, get_last_states\n",
    "from model import CirclePF, CirclePB, NeuralNet\n",
    "from sampling import (\n",
    "    sample_trajectories,\n",
    "    evaluate_backward_logprobs,\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    fit_kde,\n",
    "    plot_reward,\n",
    "    sample_from_reward,\n",
    "    plot_samples,\n",
    "    estimate_jsd,\n",
    "    plot_trajectories,\n",
    ")\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c1b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\", type=str, default=config.DEVICE)\n",
    "parser.add_argument(\"--dim\", type=int, default=config.DIM)\n",
    "parser.add_argument(\"--delta\", type=float, default=config.DELTA)\n",
    "parser.add_argument(\n",
    "    \"--n_components\",\n",
    "    type=int,\n",
    "    default=config.N_COMPONENTS,\n",
    "    help=\"Number of components in Mixture Of Betas\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--reward_debug\", action=\"store_true\", default=config.REWARD_DEBUG)\n",
    "parser.add_argument(\n",
    "    \"--reward_type\",\n",
    "    type=str,\n",
    "    choices=[\"baseline\", \"ring\", \"angular_ring\", \"multi_ring\", \"curve\", \"gaussian_mixture\", \"corner_squares\", \"two_corners\", \"edge_boxes\", \"edge_boxes_corner_squares\"],\n",
    "    default=config.REWARD_TYPE,\n",
    "    help=\"Type of reward function to use. To modify reward-specific parameters (radius, sigma, etc.), edit rewards.py\"\n",
    ")\n",
    "parser.add_argument(\"--R0\", type=float, default=config.R0, help=\"Baseline reward value\")\n",
    "parser.add_argument(\"--R1\", type=float, default=config.R1, help=\"Medium reward value (e.g., outer square)\")\n",
    "parser.add_argument(\"--R2\", type=float, default=config.R2, help=\"High reward value (e.g., inner square)\")\n",
    "parser.add_argument(\n",
    "    \"--n_components_s0\",\n",
    "    type=int,\n",
    "    default=config.N_COMPONENTS_S0,\n",
    "    help=\"Number of components in Mixture Of Betas\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_min\",\n",
    "    type=float,\n",
    "    default=config.BETA_MIN,\n",
    "    help=\"Minimum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_max\",\n",
    "    type=float,\n",
    "    default=config.BETA_MAX,\n",
    "    help=\"Maximum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--PB\",\n",
    "    type=str,\n",
    "    choices=[\"learnable\", \"tied\", \"uniform\"],\n",
    "    default=config.PB,\n",
    ")\n",
    "parser.add_argument(\"--gamma_scheduler\", type=float, default=config.GAMMA_SCHEDULER)\n",
    "parser.add_argument(\"--scheduler_milestone\", type=int, default=config.SCHEDULER_MILESTONE)\n",
    "parser.add_argument(\"--seed\", type=int, default=config.SEED)\n",
    "parser.add_argument(\"--lr\", type=float, default=config.LR)\n",
    "parser.add_argument(\"--lr_Z\", type=float, default=config.LR_Z)\n",
    "parser.add_argument(\"--lr_F\", type=float, default=config.LR_F)\n",
    "parser.add_argument(\"--tie_F\", action=\"store_true\", default=config.TIE_F)\n",
    "parser.add_argument(\"--BS\", type=int, default=config.BS)\n",
    "parser.add_argument(\"--n_iterations\", type=int, default=config.N_ITERATIONS)\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=config.HIDDEN_DIM)\n",
    "parser.add_argument(\"--n_hidden\", type=int, default=config.N_HIDDEN)\n",
    "parser.add_argument(\"--n_evaluation_trajectories\", type=int, default=config.N_EVALUATION_TRAJECTORIES)\n",
    "parser.add_argument(\"--no_plot\", action=\"store_true\", default=config.NO_PLOT)\n",
    "parser.add_argument(\"--no_wandb\", action=\"store_true\", default=config.NO_WANDB)\n",
    "parser.add_argument(\"--wandb_project\", type=str, default=config.WANDB_PROJECT)\n",
    "\n",
    "# Use parse_args([]) in Jupyter to avoid conflicts with Jupyter's kernel arguments\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "229b8a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = args.device\n",
    "dim = args.dim\n",
    "delta = args.delta\n",
    "seed = args.seed\n",
    "lr = args.lr\n",
    "lr_Z = args.lr_Z\n",
    "lr_F = args.lr_F\n",
    "n_iterations = args.n_iterations\n",
    "BS = args.BS\n",
    "n_components = args.n_components\n",
    "n_components_s0 = args.n_components_s0\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "env = Box(\n",
    "    dim=dim,\n",
    "    delta=delta,\n",
    "    device_str=device,\n",
    "    reward_type=args.reward_type,\n",
    "    reward_debug=args.reward_debug,\n",
    "    R0=args.R0,\n",
    "    R1=args.R1,\n",
    "    R2=args.R2,\n",
    ")\n",
    "\n",
    "# Get the true KDE\n",
    "samples = sample_from_reward(env, n_samples=10000)\n",
    "true_kde, fig1 = fit_kde(samples, plot=True)\n",
    "\n",
    "\n",
    "model = CirclePF(\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    n_hidden=args.n_hidden,\n",
    "    n_components=n_components,\n",
    "    n_components_s0=n_components_s0,\n",
    "    beta_min=args.beta_min,\n",
    "    beta_max=args.beta_max,\n",
    ").to(device)\n",
    "\n",
    "bw_model = CirclePB(\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    n_hidden=args.n_hidden,\n",
    "    torso=model.torso if args.PB == \"tied\" else None,\n",
    "    uniform=args.PB == \"uniform\",\n",
    "    n_components=n_components,\n",
    "    beta_min=args.beta_min,\n",
    "    beta_max=args.beta_max,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "logZ = torch.zeros(1, requires_grad=True, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "if args.PB != \"uniform\":\n",
    "    optimizer.add_param_group(\n",
    "        {\n",
    "            \"params\": bw_model.output_layer.parameters()\n",
    "            if args.PB == \"tied\"\n",
    "            else bw_model.parameters(),\n",
    "            \"lr\": lr,\n",
    "        }\n",
    "    )\n",
    "optimizer.add_param_group({\"params\": [logZ], \"lr\": lr_Z})\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[i * args.scheduler_milestone for i in range(1, 10)],\n",
    "    gamma=args.gamma_scheduler,\n",
    ")\n",
    "\n",
    "jsd = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2b5e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0547, 0.0772],\n",
      "        [0.2881, 0.1668],\n",
      "        [0.4994, 0.3005],\n",
      "        [0.6544, 0.4965],\n",
      "        [0.7699, 0.7183],\n",
      "        [  -inf,   -inf],\n",
      "        [  -inf,   -inf]], device='cuda:0')\n",
      "tensor([[0.0547, 0.0772],\n",
      "        [0.2334, 0.0896],\n",
      "        [0.2112, 0.1337],\n",
      "        [0.1551, 0.1961],\n",
      "        [0.1154, 0.2218],\n",
      "        [  -inf,   -inf],\n",
      "        [  -inf,   -inf]], device='cuda:0')\n",
      "tensor([0.0000, 2.2548, 1.3788, 1.4409, 1.1008,   -inf], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in trange(n_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    trajectories, actionss, logprobs, all_logprobs = sample_trajectories(\n",
    "        env,\n",
    "        model,\n",
    "        BS,\n",
    "    )\n",
    "\n",
    "\n",
    "    last_states = get_last_states(env, trajectories)\n",
    "    logrewards = env.reward(last_states).log()\n",
    "    bw_logprobs, all_bw_logprobs = evaluate_backward_logprobs(\n",
    "        env, bw_model, trajectories\n",
    "    )\n",
    "    print(trajectories[1])\n",
    "    print(actionss[1])\n",
    "    print(all_bw_logprobs[1])\n",
    "    break\n",
    "    # TB (Trajectory Balance) loss\n",
    "    loss = torch.mean((logZ + logprobs - bw_logprobs - logrewards) ** 2)\n",
    "\n",
    "    if torch.isinf(loss):\n",
    "        raise ValueError(\"Infinite loss\")\n",
    "    loss.backward()\n",
    "    # clip the gradients for bw_model\n",
    "    for p in bw_model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.data.clamp_(-10, 10).nan_to_num_(0.0)\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.data.clamp_(-10, 10).nan_to_num_(0.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if any(\n",
    "        [\n",
    "            torch.isnan(list(model.parameters())[i]).any()\n",
    "            for i in range(len(list(model.parameters())))\n",
    "        ]\n",
    "    ):\n",
    "        raise ValueError(\"NaN in model parameters\")\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        log_dict = {\n",
    "            \"loss\": loss.item(),\n",
    "            \"sqrt(logZdiff**2)\": np.sqrt((np.log(env.Z) - logZ.item())**2),\n",
    "            \"states_visited\": (i + 1) * BS,\n",
    "        }\n",
    "\n",
    "        # Evaluate JSD every 500 iterations and add to the same log\n",
    "        if i % 500 == 0:\n",
    "            trajectories, _, _, _ = sample_trajectories(\n",
    "                env, model, args.n_evaluation_trajectories\n",
    "            )\n",
    "            last_states = get_last_states(env, trajectories)\n",
    "            kde, fig4 = fit_kde(last_states, plot=True)\n",
    "            jsd = estimate_jsd(kde, true_kde)\n",
    "\n",
    "            log_dict[\"JSD\"] = jsd\n",
    "\n",
    "            if not NO_PLOT:\n",
    "                colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "                fig1 = plot_samples(last_states[:2000].detach().cpu().numpy())\n",
    "                fig2 = plot_trajectories(trajectories.detach().cpu().numpy()[:20])\n",
    "\n",
    "                log_dict[\"last_states\"] = wandb.Image(fig1)\n",
    "                log_dict[\"trajectories\"] = wandb.Image(fig2)\n",
    "                log_dict[\"kde\"] = wandb.Image(fig4)\n",
    "\n",
    "        if USE_WANDB:\n",
    "            wandb.log(log_dict, step=i)\n",
    "\n",
    "        tqdm.write(\n",
    "            # Loss with 3 digits of precision, logZ with 2 digits of precision, true logZ with 2 digits of precision\n",
    "            # Last computed JSD with 4 digits of precision\n",
    "            f\"States: {(i + 1) * BS}, Loss: {loss.item():.3f}, logZ: {logZ.item():.2f}, true logZ: {np.log(env.Z):.2f}, JSD: {jsd:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# if USE_WANDB:\n",
    "#     wandb.finish()\n",
    "\n",
    "# # Save model and arguments as JSON\n",
    "# save_path = os.path.join(\"saved_models\", run_name)\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "#     torch.save(model.state_dict(), os.path.join(save_path, \"model.pt\"))\n",
    "#     torch.save(bw_model.state_dict(), os.path.join(save_path, \"bw_model.pt\"))\n",
    "#     torch.save(logZ, os.path.join(save_path, \"logZ.pt\"))\n",
    "#     with open(os.path.join(save_path, \"args.json\"), \"w\") as f:\n",
    "#         json.dump(vars(args), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4ac6bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trajectories_to_transitions(trajectories, actionss, all_bw_logprobs, logrewards, env):\n",
    "    \"\"\"\n",
    "    Convert trajectories to transitions for replay buffer.\n",
    "\n",
    "    Args:\n",
    "        trajectories: tensor of shape (batch_size, trajectory_length, dim)\n",
    "        actionss: tensor of shape (batch_size, trajectory_length, dim)\n",
    "        all_bw_logprobs: tensor of shape (batch_size, trajectory_length)\n",
    "        last_states: tensor of shape (batch_size, dim)\n",
    "        logrewards: tensor of shape (batch_size,)\n",
    "        env: environment object\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (states, actions, rewards, next_states, dones) as tensors\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract states and next_states for intermediate transitions\n",
    "    # Match the length to all_bw_logprobs\n",
    "\n",
    "    states = trajectories[:, :-1, :]  \n",
    "    next_states = trajectories[:, 1:, :] \n",
    "    is_not_sink = torch.all(states != env.sink_state, dim=-1)\n",
    "    is_next_sink = torch.all(next_states == env.sink_state, dim=-1)\n",
    "    last_state = is_not_sink & is_next_sink\n",
    "    dones = torch.zeros_like(last_state, dtype=torch.float32)  # (batch_size, bw_length)\n",
    "    dones[last_state] = 1.0\n",
    "    dones = dones[:, 1:]\n",
    "    rewards = all_bw_logprobs\n",
    "    rewards = torch.where(last_state[:,1:], rewards + logrewards.unsqueeze(1), rewards)\n",
    "    states = states[:, :-1, :]  \n",
    "    next_states = next_states[:, :-1, :] \n",
    "    actions = actionss[:, :-1, :] \n",
    "    # Check which rewards are valid (not inf/nan)\n",
    "    is_valid = torch.isfinite(rewards)  # (batch_size, bw_length)\n",
    "\n",
    "    # Flatten batch and time dimensions for transitions\n",
    "    states_flat = states[is_valid]\n",
    "    actions_flat = actions[is_valid]\n",
    "    rewards_flat = rewards[is_valid]\n",
    "    next_states_flat = next_states[is_valid]\n",
    "    dones_flat = dones[is_valid]\n",
    "\n",
    "    return states_flat, actions_flat, rewards_flat, next_states_flat, dones_flat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8ac2157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0===\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "tensor([0.0515, 0.0231], device='cuda:0')\n",
      "tensor(1., device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.0515, 0.0231], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===1===\n",
      "tensor([0.0515, 0.0231], device='cuda:0')\n",
      "tensor([0.1983, 0.1522], device='cuda:0')\n",
      "tensor(3.4034, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.2498, 0.1753], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===2===\n",
      "tensor([0.2498, 0.1753], device='cuda:0')\n",
      "tensor([0.1348, 0.2105], device='cuda:0')\n",
      "tensor(3.8133, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.3846, 0.3859], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===3===\n",
      "tensor([0.3846, 0.3859], device='cuda:0')\n",
      "tensor([0.1413, 0.2063], device='cuda:0')\n",
      "tensor(3.9550, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.5259, 0.5921], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===4===\n",
      "tensor([0.5259, 0.5921], device='cuda:0')\n",
      "tensor([0.2142, 0.1288], device='cuda:0')\n",
      "tensor(3.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.7402, 0.7210], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===5===\n",
      "tensor([0.7402, 0.7210], device='cuda:0')\n",
      "tensor([0.1813, 0.1721], device='cuda:0')\n",
      "tensor(218.5743, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.9215, 0.8930], device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "===6===\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "tensor([0.0447, 0.0762], device='cuda:0')\n",
      "tensor(1., device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.0447, 0.0762], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===7===\n",
      "tensor([0.0447, 0.0762], device='cuda:0')\n",
      "tensor([0.1100, 0.2245], device='cuda:0')\n",
      "tensor(8.5290, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.1547, 0.3007], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===8===\n",
      "tensor([0.1547, 0.3007], device='cuda:0')\n",
      "tensor([0.1569, 0.1946], device='cuda:0')\n",
      "tensor(4.2486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.3116, 0.4953], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===9===\n",
      "tensor([0.3116, 0.4953], device='cuda:0')\n",
      "tensor([0.1509, 0.1993], device='cuda:0')\n",
      "tensor(4.1450, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.4626, 0.6946], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===10===\n",
      "tensor([0.4626, 0.6946], device='cuda:0')\n",
      "tensor([0.2444, 0.0524], device='cuda:0')\n",
      "tensor(1.4041, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.7070, 0.7471], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===11===\n",
      "tensor([0.7070, 0.7471], device='cuda:0')\n",
      "tensor([0.1234, 0.2174], device='cuda:0')\n",
      "tensor(0.8041, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.8304, 0.9645], device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "===12===\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "tensor([0.0888, 0.0397], device='cuda:0')\n",
      "tensor(1., device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.0888, 0.0397], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===13===\n",
      "tensor([0.0888, 0.0397], device='cuda:0')\n",
      "tensor([0.2014, 0.1481], device='cuda:0')\n",
      "tensor(5.0174, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.2902, 0.1878], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "===14===\n",
      "tensor([0.2902, 0.1878], device='cuda:0')\n",
      "tensor([0.2145, 0.1284], device='cuda:0')\n",
      "tensor(3.8501, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "tensor([0.5047, 0.3162], device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in trange(n_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    trajectories, actionss, logprobs, all_logprobs = sample_trajectories(\n",
    "        env,\n",
    "        model,\n",
    "        BS,\n",
    "    )\n",
    "\n",
    "    last_states = get_last_states(env, trajectories)\n",
    "    logrewards = env.reward(last_states).log()\n",
    "    bw_logprobs, all_bw_logprobs = evaluate_backward_logprobs(\n",
    "        env, bw_model, trajectories\n",
    "    )\n",
    "    all_states, all_actions, all_rewards, all_next_states, all_dones = trajectories_to_transitions(\n",
    "        trajectories, actionss, all_bw_logprobs, logrewards, env\n",
    "    )\n",
    "\n",
    "\n",
    "    for i in range(15):\n",
    "        print(f\"==={i}===\")\n",
    "        print(all_states[i])\n",
    "        print(all_actions[i])\n",
    "        print(torch.exp(all_rewards[i]))\n",
    "        print(all_next_states[i])\n",
    "        print(all_dones[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f43b5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Beta\n",
    "\n",
    "\n",
    "class CirclePF_Uniform():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def to_dist(self, x):\n",
    "        if torch.all(x[0] == 0.0):\n",
    "            assert torch.all(\n",
    "                x == 0.0\n",
    "            )  # If one of the states is s0, all of them must be\n",
    "            alpha = torch.ones(x.shape[0], device=x.device)\n",
    "            beta = torch.ones(x.shape[0], device=x.device)\n",
    "            \n",
    "            return Beta(alpha, beta), Beta(alpha, beta)\n",
    "        \n",
    "        alpha = torch.ones(x.shape[0], device=x.device)\n",
    "        beta = torch.ones(x.shape[0], device=x.device)\n",
    "        return Beta(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54b4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6858])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca82a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CGFN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
