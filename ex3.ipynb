{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e20f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pickle import TRUE\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import argparse\n",
    "\n",
    "from env import Box, get_last_states\n",
    "from model import CirclePF, CirclePB, NeuralNet\n",
    "from sampling import (\n",
    "    sample_trajectories,\n",
    "    evaluate_backward_logprobs,\n",
    "    evaluate_state_flows,\n",
    "    evaluate_forward_logprobs,\n",
    ")\n",
    "from replay_memory import TrajectoryReplayMemory\n",
    "\n",
    "from utils import (\n",
    "    fit_kde,\n",
    "    plot_reward,\n",
    "    sample_from_reward,\n",
    "    plot_samples,\n",
    "    estimate_jsd,\n",
    "    plot_trajectories,\n",
    ")\n",
    "\n",
    "import config\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\", type=str, default=config.DEVICE)\n",
    "parser.add_argument(\"--dim\", type=int, default=config.DIM)\n",
    "parser.add_argument(\"--delta\", type=float, default=config.DELTA)\n",
    "parser.add_argument(\n",
    "    \"--n_components\",\n",
    "    type=int,\n",
    "    default=config.N_COMPONENTS,\n",
    "    help=\"Number of components in Mixture Of Betas\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--reward_debug\", action=\"store_true\", default=config.REWARD_DEBUG)\n",
    "parser.add_argument(\n",
    "    \"--reward_type\",\n",
    "    type=str,\n",
    "    choices=[\"baseline\", \"ring\", \"angular_ring\", \"multi_ring\", \"curve\", \"gaussian_mixture\", \"corner_squares\", \"two_corners\", \"edge_boxes\", \"edge_boxes_corner_squares\"],\n",
    "    default=config.REWARD_TYPE,\n",
    "    help=\"Type of reward function to use. To modify reward-specific parameters (radius, sigma, etc.), edit rewards.py\"\n",
    ")\n",
    "parser.add_argument(\"--R0\", type=float, default=config.R0, help=\"Baseline reward value\")\n",
    "parser.add_argument(\"--R1\", type=float, default=config.R1, help=\"Medium reward value (e.g., outer square)\")\n",
    "parser.add_argument(\"--R2\", type=float, default=config.R2, help=\"High reward value (e.g., inner square)\")\n",
    "parser.add_argument(\n",
    "    \"--n_components_s0\",\n",
    "    type=int,\n",
    "    default=config.N_COMPONENTS_S0,\n",
    "    help=\"Number of components in Mixture Of Betas\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_min\",\n",
    "    type=float,\n",
    "    default=config.BETA_MIN,\n",
    "    help=\"Minimum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_max\",\n",
    "    type=float,\n",
    "    default=config.BETA_MAX,\n",
    "    help=\"Maximum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--PB\",\n",
    "    type=str,\n",
    "    choices=[\"learnable\", \"tied\", \"uniform\"],\n",
    "    default=config.PB,\n",
    ")\n",
    "parser.add_argument(\"--loss\", type=str, choices=[\"tb\", \"db\"], default=config.LOSS)\n",
    "parser.add_argument(\"--gamma_scheduler\", type=float, default=config.GAMMA_SCHEDULER)\n",
    "parser.add_argument(\"--scheduler_milestone\", type=int, default=config.SCHEDULER_MILESTONE)\n",
    "parser.add_argument(\"--seed\", type=int, default=config.SEED)\n",
    "parser.add_argument(\"--lr\", type=float, default=config.LR)\n",
    "parser.add_argument(\"--lr_Z\", type=float, default=config.LR_Z)\n",
    "parser.add_argument(\"--lr_F\", type=float, default=config.LR_F)\n",
    "parser.add_argument(\"--alpha\", type=float, default=config.ALPHA)\n",
    "parser.add_argument(\"--tie_F\", action=\"store_true\", default=config.TIE_F)\n",
    "parser.add_argument(\"--BS\", type=int, default=config.BS)\n",
    "parser.add_argument(\"--n_iterations\", type=int, default=config.N_ITERATIONS)\n",
    "parser.add_argument(\"--n_evaluation_interval\", type=int, default=config.N_EVALUATION_INTERVAL)\n",
    "parser.add_argument(\"--n_logging_interval\", type=int, default=config.N_LOGGING_INTERVAL)\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=config.HIDDEN_DIM)\n",
    "parser.add_argument(\"--n_hidden\", type=int, default=config.N_HIDDEN)\n",
    "parser.add_argument(\"--n_evaluation_trajectories\", type=int, default=config.N_EVALUATION_TRAJECTORIES)\n",
    "parser.add_argument(\"--no_plot\", action=\"store_true\", default=config.NO_PLOT)\n",
    "parser.add_argument(\"--no_wandb\", action=\"store_true\", default=config.NO_WANDB)\n",
    "parser.add_argument(\"--wandb_project\", type=str, default=config.WANDB_PROJECT)\n",
    "parser.add_argument(\"--uniform_ratio\", type=float, default=config.UNIFORM_RATIO)\n",
    "parser.add_argument(\"--replay_size\", type=int, default=config.REPLAY_SIZE)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "\n",
    "device = args.device\n",
    "dim = args.dim\n",
    "delta = args.delta\n",
    "seed = args.seed\n",
    "lr = args.lr\n",
    "lr_Z = args.lr_Z\n",
    "lr_F = args.lr_F\n",
    "n_iterations = args.n_iterations\n",
    "BS = args.BS\n",
    "n_components = args.n_components\n",
    "n_components_s0 = args.n_components_s0\n",
    "\n",
    "if seed == 0:\n",
    "    seed = np.random.randint(int(1e6))\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd25f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = Box(\n",
    "    dim=dim,\n",
    "    delta=delta,\n",
    "    device_str=device,\n",
    "    reward_type=args.reward_type,\n",
    "    reward_debug=args.reward_debug,\n",
    "    R0=args.R0,\n",
    "    R1=args.R1,\n",
    "    R2=args.R2,\n",
    ")\n",
    "\n",
    "# Get the true KDE\n",
    "samples = sample_from_reward(env, n_samples=10000)\n",
    "true_kde, fig1 = fit_kde(samples, plot=True)\n",
    "\n",
    "\n",
    "\n",
    "model = CirclePF(\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    n_hidden=args.n_hidden,\n",
    "    n_components=n_components,\n",
    "    n_components_s0=n_components_s0,\n",
    "    beta_min=args.beta_min,\n",
    "    beta_max=args.beta_max,\n",
    "    uniform = False,\n",
    ").to(device)\n",
    "\n",
    "bw_model = CirclePB(\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    n_hidden=args.n_hidden,\n",
    "    torso=model.torso if args.PB == \"tied\" else None,\n",
    "    uniform=args.PB == \"uniform\",\n",
    "    n_components=n_components,\n",
    "    beta_min=args.beta_min,\n",
    "    beta_max=args.beta_max,\n",
    ").to(device)\n",
    "\n",
    "if args.loss == \"db\":\n",
    "    flow_model = NeuralNet(\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        n_hidden=args.n_hidden,\n",
    "        torso=None if not args.tie_F else model.torso,\n",
    "        output_dim=1,\n",
    "    ).to(device)\n",
    "\n",
    "logZ = torch.zeros(1, requires_grad=True, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "if args.PB != \"uniform\":\n",
    "    optimizer.add_param_group(\n",
    "        {\n",
    "            \"params\": bw_model.output_layer.parameters()\n",
    "            if args.PB == \"tied\"\n",
    "            else bw_model.parameters(),\n",
    "            \"lr\": lr,\n",
    "        }\n",
    "    )\n",
    "optimizer.add_param_group({\"params\": [logZ], \"lr\": lr_Z})\n",
    "\n",
    "if args.loss == \"db\":\n",
    "    optimizer.add_param_group(\n",
    "        {\n",
    "            \"params\": flow_model.output_layer.parameters()\n",
    "            if args.tie_F\n",
    "            else flow_model.parameters(),\n",
    "            \"lr\": lr_F,\n",
    "        }\n",
    "    )\n",
    "    print(\"using flow model\")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[i * args.scheduler_milestone for i in range(1, 10)],\n",
    "    gamma=args.gamma_scheduler,\n",
    ")\n",
    "\n",
    "jsd = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41abc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 0 ===\n",
      "Sampled trajectories shape: torch.Size([1, 7, 2])\n",
      "Sampled sampless shape: torch.Size([1, 6, 2])\n",
      "Memory size before push: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrajectoryReplayMemory.push_batch() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled sampless shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampless\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory size before push: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(memory)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampless\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory size after push: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(memory)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m retrieved_trajectories, retrieved_sampless \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TrajectoryReplayMemory.push_batch() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "memory = TrajectoryReplayMemory(3, seed, device)\n",
    "\n",
    "for i in trange(10):\n",
    "    optimizer.zero_grad()\n",
    "    if np.random.rand() < args.uniform_ratio: \n",
    "        model.uniform = True\n",
    "        trajectories, _, sampless = sample_trajectories(\n",
    "            env,\n",
    "            model,\n",
    "            1,\n",
    "        )\n",
    "    else:\n",
    "        model.uniform = False\n",
    "        trajectories, _, sampless = sample_trajectories(\n",
    "            env,\n",
    "            model,\n",
    "            1,\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n=== Iteration {i} ===\")\n",
    "    print(f\"Sampled trajectories shape: {trajectories.shape}\")\n",
    "    print(f\"Sampled sampless shape: {sampless.shape}\")\n",
    "    print(f\"Memory size before push: {len(memory)}\")\n",
    "    \n",
    "    memory.push_batch(trajectories, sampless)\n",
    "    \n",
    "    print(f\"Memory size after push: {len(memory)}\")\n",
    "    \n",
    "    retrieved_trajectories, retrieved_sampless = memory.sample(1)\n",
    "    \n",
    "    print(f\"Retrieved trajectories shape: {retrieved_trajectories.shape}\")\n",
    "    print(f\"Retrieved sampless shape: {retrieved_sampless.shape}\")\n",
    "    print(f\"Are retrieved same as sampled? {torch.allclose(trajectories, retrieved_trajectories) if trajectories.shape == retrieved_trajectories.shape else 'Different shapes'}\")\n",
    "\n",
    "    while torch.all(retrieved_trajectories[:,-2,:] == env.sink_state):\n",
    "        retrieved_trajectories = retrieved_trajectories[:,:-1,:]\n",
    "        retrieved_sampless = retrieved_sampless[:,:-1,:]\n",
    "    print(retrieved_trajectories, '\\n', retrieved_sampless)\n",
    "    \n",
    "    print(f\"Final trajectories shape after trimming: {retrieved_trajectories.shape}\")\n",
    "    print(f\"Final sampless shape after trimming: {retrieved_sampless.shape}\")\n",
    "    print(memory.trajectories, '\\n', memory.samples)\n",
    "    logprobs, all_logprobs = evaluate_forward_logprobs(env, model, retrieved_trajectories, retrieved_sampless)\n",
    "\n",
    "    # Store trajectories in replay buffer\n",
    "    last_states = get_last_states(env, retrieved_trajectories)\n",
    "    logrewards = env.reward(last_states).log()\n",
    "    bw_logprobs, all_bw_logprobs = evaluate_backward_logprobs(\n",
    "        env, bw_model, retrieved_trajectories\n",
    "    )\n",
    "\n",
    "    # TB (Trajectory Balance) loss\n",
    "    if args.loss == \"tb\":\n",
    "        loss = torch.mean((logZ + logprobs - bw_logprobs - logrewards) ** 2)\n",
    "\n",
    "    elif args.loss == \"db\":\n",
    "        log_state_flows = evaluate_state_flows(env, flow_model, retrieved_trajectories, logZ)  # type: ignore\n",
    "        db_preds = all_logprobs + log_state_flows\n",
    "        db_targets = all_bw_logprobs + log_state_flows[:, 1:]\n",
    "        if args.alpha == 1.0:\n",
    "            db_targets = torch.cat(\n",
    "                [\n",
    "                    db_targets,\n",
    "                    torch.full(\n",
    "                        (db_targets.shape[0], 1),\n",
    "                        -float(\"inf\"),\n",
    "                        device=db_targets.device,\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "            infinity_mask = db_targets == -float(\"inf\")\n",
    "            _, indices_of_first_inf = torch.max(infinity_mask, dim=1)\n",
    "            db_targets = db_targets.scatter(\n",
    "                1, indices_of_first_inf.unsqueeze(1), logrewards.unsqueeze(1)\n",
    "            )\n",
    "            flat_db_preds = db_preds[db_preds != -float(\"inf\")]\n",
    "            flat_db_targets = db_targets[db_targets != -float(\"inf\")]\n",
    "            loss = torch.mean((flat_db_preds - flat_db_targets) ** 2)\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    \n",
    "    if torch.isinf(loss):\n",
    "        raise ValueError(\"Infinite loss\")\n",
    "    loss.backward()\n",
    "    # clip the gradients for bw_model\n",
    "    for p in bw_model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.data.clamp_(-10, 10).nan_to_num_(0.0)\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.data.clamp_(-10, 10).nan_to_num_(0.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if any(\n",
    "        [\n",
    "            torch.isnan(list(model.parameters())[i]).any()\n",
    "            for i in range(len(list(model.parameters())))\n",
    "        ]\n",
    "    ):\n",
    "        raise ValueError(\"NaN in model parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04793f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74d561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad388ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CGFN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
