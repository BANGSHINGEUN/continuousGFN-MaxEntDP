{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4960ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import argparse\n",
    "\n",
    "from env import Box, get_last_states\n",
    "from sac_model import CirclePB, Uniform\n",
    "from sac_sampling import (\n",
    "    sample_trajectories,\n",
    "    evaluate_backward_logprobs,\n",
    ")\n",
    "from sac import SAC\n",
    "from sac_replay_memory import ReplayMemory, trajectories_to_transitions\n",
    "\n",
    "from utils import (\n",
    "    fit_kde,\n",
    "    plot_reward,\n",
    "    sample_from_reward,\n",
    "    plot_samples,\n",
    "    estimate_jsd,\n",
    "    plot_trajectories,\n",
    ")\n",
    "\n",
    "import config\n",
    "import sac_config\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\", type=str, default=sac_config.DEVICE)\n",
    "parser.add_argument(\"--dim\", type=int, default=config.DIM)\n",
    "parser.add_argument(\"--delta\", type=float, default=config.DELTA)\n",
    "parser.add_argument(\"--epsilon\", type=float, default=config.EPSILON)\n",
    "parser.add_argument(\"--R0\", type=float, default=config.R0, help=\"Baseline reward value\")\n",
    "parser.add_argument(\"--R1\", type=float, default=config.R1, help=\"Medium reward value (e.g., outer square)\")\n",
    "parser.add_argument(\"--R2\", type=float, default=config.R2, help=\"High reward value (e.g., inner square)\")\n",
    "parser.add_argument(\"--reward_debug\", action=\"store_true\", default=config.REWARD_DEBUG)\n",
    "parser.add_argument(\n",
    "    \"--reward_type\",\n",
    "    type=str,\n",
    "    choices=[\"baseline\", \"ring\", \"angular_ring\", \"multi_ring\", \"curve\", \"gaussian_mixture\"],\n",
    "    default=config.REWARD_TYPE,\n",
    "    help=\"Type of reward function to use. To modify reward-specific parameters (radius, sigma, etc.), edit rewards.py\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_min\",\n",
    "    type=float,\n",
    "    default=config.BETA_MIN,\n",
    "    help=\"Minimum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--beta_max\",\n",
    "    type=float, \n",
    "    default=config.BETA_MAX,\n",
    "    help=\"Maximum value for the concentration parameters of the Beta distribution\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--PB\",\n",
    "    type=str,\n",
    "    choices=[\"learnable\", \"tied\", \"uniform\"],\n",
    "    default=config.PB,\n",
    "    help=\"Backward policy type\",\n",
    ")\n",
    "parser.add_argument(\"--gamma_scheduler\", type=float, default=config.GAMMA_SCHEDULER)\n",
    "parser.add_argument(\"--scheduler_milestone\", type=int, default=config.SCHEDULER_MILESTONE)\n",
    "parser.add_argument(\"--seed\", type=int, default=config.SEED)\n",
    "parser.add_argument(\"--lr\", type=float, default=config.LR, help=\"Learning rate for SAC\")\n",
    "parser.add_argument(\"--BS\", type=int, default=config.BS)\n",
    "parser.add_argument(\"--n_iterations\", type=int, default=config.N_ITERATIONS)\n",
    "parser.add_argument(\"--n_evaluation_interval\", type=int, default=config.N_EVALUATION_INTERVAL)\n",
    "parser.add_argument(\"--n_logging_interval\", type=int, default=config.N_LOGGING_INTERVAL)\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=config.HIDDEN_DIM)\n",
    "parser.add_argument(\"--n_hidden\", type=int, default=config.N_HIDDEN)\n",
    "parser.add_argument(\"--n_evaluation_trajectories\", type=int, default=config.N_EVALUATION_TRAJECTORIES)\n",
    "parser.add_argument(\"--no_plot\", action=\"store_true\", default=config.NO_PLOT)\n",
    "parser.add_argument(\"--no_wandb\", action=\"store_true\", default=config.NO_WANDB)\n",
    "parser.add_argument(\"--wandb_project\", type=str, default=config.WANDB_PROJECT)\n",
    "parser.add_argument(\"--uniform_ratio\", type=float, default=config.UNIFORM_RATIO, help=\"Ratio of uniform policy\")\n",
    "\n",
    "\n",
    "# SAC-specific arguments\n",
    "parser.add_argument(\"--tau\", type=float, default=sac_config.TAU, help=\"Tau for soft update\")\n",
    "parser.add_argument(\"--target_update_interval\", type=int, default=sac_config.TARGET_UPDATE_INTERVAL, help=\"Target network update interval\")\n",
    "parser.add_argument(\"--policy_update_interval\", type=int, default=sac_config.POLICY_UPDATE_INTERVAL, help=\"Policy update interval\")\n",
    "parser.add_argument(\"--Critic_hidden_size\", type=int, default=sac_config.CRITIC_HIDDEN_SIZE, help=\"Hidden size for SAC critic networks\")\n",
    "parser.add_argument(\"--replay_size\", type=int, default=sac_config.REPLAY_SIZE, help=\"Replay buffer size\")\n",
    "parser.add_argument(\"--sac_batch_size\", type=int, default=sac_config.SAC_BATCH_SIZE, help=\"SAC batch size\")\n",
    "parser.add_argument(\"--updates_per_step\", type=int, default=sac_config.UPDATES_PER_STEP, help=\"SAC updates per step\")\n",
    "parser.add_argument(\"--without_backward_model\", type=bool, default=sac_config.WITHOUT_BACKWARD_MODEL, help=\"Whether to use backward model\")\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795320aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC_d0.25_ring_lr0.001_sd483492_R0,R1,R2_0.1,0.5,2_tau0.1_BS256_replay_size1000000_sac_batch_size256_update_per_step5_target_update_interval5_UR0.2_devicecuda:2\n",
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = args.device\n",
    "dim = args.dim\n",
    "delta = args.delta\n",
    "epsilon = args.epsilon\n",
    "seed = args.seed\n",
    "lr = args.lr\n",
    "n_iterations = args.n_iterations\n",
    "BS = args.BS\n",
    "\n",
    "if seed == 0:\n",
    "    seed = np.random.randint(int(1e6))\n",
    "\n",
    "run_name = f\"SAC_d{delta}_{args.reward_type}_lr{lr}_sd{seed}\"\n",
    "if args.without_backward_model:\n",
    "    run_name += f\"_without_backward_model\"\n",
    "run_name += f\"_R0,R1,R2_{args.R0},{args.R1},{args.R2}\"\n",
    "run_name += f\"_tau{args.tau}\"\n",
    "run_name += f\"_BS{BS}\"\n",
    "run_name += f\"_replay_size{args.replay_size}\"\n",
    "run_name += f\"_sac_batch_size{args.sac_batch_size}\"\n",
    "run_name += f\"_update_per_step{args.updates_per_step}\"\n",
    "run_name += f\"_target_update_interval{args.target_update_interval}\"\n",
    "run_name += f\"_UR{args.uniform_ratio}\"\n",
    "run_name += f\"_device{device}\"\n",
    "print(run_name)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "env = Box(\n",
    "    dim=dim,\n",
    "    delta=delta,\n",
    "    epsilon=epsilon,\n",
    "    device_str=device,\n",
    "    reward_type=args.reward_type,\n",
    "    reward_debug=args.reward_debug,\n",
    "    R0=args.R0,\n",
    "    R1=args.R1,\n",
    "    R2=args.R2,\n",
    ")\n",
    "\n",
    "\n",
    "# Create SAC agent (includes CirclePF as policy)\n",
    "sac_agent = SAC(args, env)\n",
    "Uniform_model = Uniform()\n",
    "memory = ReplayMemory(args.replay_size, seed, device=device)\n",
    "\n",
    "bw_model = CirclePB(\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    n_hidden=args.n_hidden,\n",
    "    torso=sac_agent.policy.torso if args.PB == \"tied\" else None,\n",
    "    uniform=args.PB == \"uniform\",\n",
    "    beta_min=args.beta_min,\n",
    "    beta_max=args.beta_max,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349d4b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sac_updates = 0  # Track SAC update steps\n",
    "# Initialize loss tracking variables\n",
    "qf1_loss = 0.0\n",
    "qf2_loss = 0.0\n",
    "policy_loss = None\n",
    "\n",
    "for i in trange(1, n_iterations + 1):\n",
    "    with torch.no_grad():   # ★ 여기 추가\n",
    "        if np.random.rand() < args.uniform_ratio:\n",
    "            trajectories, actionss, _, _  = sample_trajectories(\n",
    "                env,\n",
    "                Uniform_model,\n",
    "                BS,\n",
    "            )\n",
    "        else:\n",
    "            trajectories, actionss, _, _  = sample_trajectories(\n",
    "                env,\n",
    "                sac_agent.policy,\n",
    "                BS,\n",
    "            )\n",
    "\n",
    "        last_states = get_last_states(env, trajectories)\n",
    "        logrewards = env.reward(last_states).log()\n",
    "        \n",
    "        bw_logprobs, all_bw_logprobs = evaluate_backward_logprobs(\n",
    "            env, bw_model, trajectories\n",
    "        )\n",
    "\n",
    "        if args.without_backward_model:\n",
    "            intermediate_rewards = torch.where(\n",
    "                all_bw_logprobs != -float(\"inf\"),\n",
    "                torch.zeros_like(all_bw_logprobs),\n",
    "                all_bw_logprobs,\n",
    "                )\n",
    "        else:\n",
    "            intermediate_rewards = all_bw_logprobs\n",
    "\n",
    "        # Convert trajectories to transitions and push to replay memory\n",
    "        all_states, all_actions, all_rewards, all_next_states, all_dones = trajectories_to_transitions(\n",
    "            trajectories, actionss, intermediate_rewards, logrewards, env\n",
    "        )\n",
    "    memory.push_batch(all_states, all_actions, all_rewards, all_next_states, all_dones)\n",
    "\n",
    "    if len(memory) > args.sac_batch_size:\n",
    "        # Accumulate losses over multiple updates\n",
    "        qf1_losses = []\n",
    "        qf2_losses = []\n",
    "        policy_losses = []\n",
    "        \n",
    "        for _ in range(args.updates_per_step):\n",
    "            qf1_loss_step, qf2_loss_step, policy_loss_step = sac_agent.update_parameters(memory, args.sac_batch_size, sac_updates)\n",
    "            qf1_losses.append(qf1_loss_step)\n",
    "            qf2_losses.append(qf2_loss_step)\n",
    "            if policy_loss_step is not None:\n",
    "                policy_losses.append(policy_loss_step)\n",
    "            sac_updates += 1\n",
    "        \n",
    "        # Average the losses\n",
    "        qf1_loss = sum(qf1_losses) / len(qf1_losses)\n",
    "        qf2_loss = sum(qf2_losses) / len(qf2_losses)\n",
    "        policy_loss = sum(policy_losses) / len(policy_losses) if len(policy_losses) > 0 else None\n",
    "\n",
    "    if any(\n",
    "        [\n",
    "            torch.isnan(list(sac_agent.policy.parameters())[i]).any()\n",
    "            for i in range(len(list(sac_agent.policy.parameters())))\n",
    "        ]\n",
    "    ):\n",
    "        raise ValueError(\"NaN in model parameters\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdd771e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.1174, 0.0928],\n",
       "        [0.2980, 0.2656],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf]], device='cuda:2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "504d5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1684, 0.4574],\n",
       "        [0.0992, 0.2525],\n",
       "        [0.0882, 0.1209],\n",
       "        [0.0309, 0.1111],\n",
       "        [0.0275, 0.0436],\n",
       "        [0.4047, 0.3297],\n",
       "        [0.0886, 0.0286],\n",
       "        [0.3834, 0.2544],\n",
       "        [0.1001, 0.4296],\n",
       "        [0.0021, 0.0030],\n",
       "        [0.3249, 0.1248],\n",
       "        [0.0597, 0.0507],\n",
       "        [0.2873, 0.8435],\n",
       "        [0.0445, 0.1881],\n",
       "        [0.2105, 0.4049],\n",
       "        [0.1433, 0.0220],\n",
       "        [0.0712, 0.0571],\n",
       "        [0.0688, 0.0115],\n",
       "        [0.2533, 0.0743],\n",
       "        [0.1627, 0.0208],\n",
       "        [0.0208, 0.0543],\n",
       "        [0.0034, 0.0294],\n",
       "        [0.0816, 0.0659],\n",
       "        [0.0639, 0.1013],\n",
       "        [0.0246, 0.2014],\n",
       "        [0.6037, 0.3071],\n",
       "        [0.5743, 0.1599],\n",
       "        [0.5024, 0.4289],\n",
       "        [0.0909, 0.0981],\n",
       "        [0.0485, 0.0140],\n",
       "        [0.0941, 0.0775],\n",
       "        [0.8887, 0.8427],\n",
       "        [0.1823, 0.0887],\n",
       "        [0.0364, 0.1095],\n",
       "        [0.0800, 0.0409],\n",
       "        [0.8634, 0.9678],\n",
       "        [0.5422, 0.5688],\n",
       "        [0.2534, 0.2848],\n",
       "        [0.0445, 0.1120],\n",
       "        [0.0991, 0.1007],\n",
       "        [0.1006, 0.2022],\n",
       "        [0.6122, 0.3119],\n",
       "        [0.0135, 0.0063],\n",
       "        [0.5689, 0.7476],\n",
       "        [0.2752, 0.0878],\n",
       "        [0.0095, 0.0965],\n",
       "        [0.2396, 0.0672],\n",
       "        [0.0105, 0.0275],\n",
       "        [0.4587, 0.2319],\n",
       "        [0.4926, 0.5617],\n",
       "        [0.1284, 0.2238],\n",
       "        [0.0045, 0.0070],\n",
       "        [0.0517, 0.2515],\n",
       "        [0.0734, 0.0366],\n",
       "        [0.0854, 0.0580],\n",
       "        [0.1357, 0.0219],\n",
       "        [0.0299, 0.1055],\n",
       "        [0.1358, 0.0791],\n",
       "        [0.0876, 0.0739],\n",
       "        [0.3883, 0.4565],\n",
       "        [0.0594, 0.0244],\n",
       "        [0.3793, 0.2747],\n",
       "        [0.3767, 0.0723],\n",
       "        [0.8835, 0.7866],\n",
       "        [0.3873, 0.1741],\n",
       "        [0.2779, 0.3595],\n",
       "        [0.0181, 0.0132],\n",
       "        [0.3794, 0.4813],\n",
       "        [0.6829, 0.7645],\n",
       "        [0.5326, 0.5809],\n",
       "        [0.1556, 0.0732],\n",
       "        [0.4456, 0.5372],\n",
       "        [0.2724, 0.3416],\n",
       "        [0.2606, 0.3512],\n",
       "        [0.2923, 0.5416],\n",
       "        [0.5046, 0.4180],\n",
       "        [0.0193, 0.0365],\n",
       "        [0.0196, 0.0046],\n",
       "        [0.0749, 0.0919],\n",
       "        [0.2764, 0.8322],\n",
       "        [0.1509, 0.1546],\n",
       "        [0.0413, 0.1289],\n",
       "        [0.6760, 0.5029],\n",
       "        [0.1057, 0.4108],\n",
       "        [0.1199, 0.1478],\n",
       "        [0.8126, 0.7969],\n",
       "        [0.2426, 0.2660],\n",
       "        [0.7561, 0.9097],\n",
       "        [0.4309, 0.4515],\n",
       "        [0.1978, 0.2976],\n",
       "        [0.1384, 0.0367],\n",
       "        [0.0789, 0.4986],\n",
       "        [0.1040, 0.1004],\n",
       "        [0.1849, 0.0293],\n",
       "        [0.0350, 0.2986],\n",
       "        [0.0523, 0.0153],\n",
       "        [0.7623, 0.9012],\n",
       "        [0.2175, 0.2051],\n",
       "        [0.9216, 0.1889],\n",
       "        [0.2980, 0.2656]], device='cuda:2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_states[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "174d7d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1319, -2.3026, -2.3026, -2.3026, -2.3026, -2.2589, -2.3026,  0.3275,\n",
       "        -2.2647, -2.3026], device='cuda:2')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrewards[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7e7aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.0858, 0.0235],\n",
       "        [0.1644, 0.2608],\n",
       "        [0.4047, 0.3297],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf],\n",
       "        [  -inf,   -inf]], device='cuda:2')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f494c2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.6884,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000, 2.2829,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000, 1.7183, 0.9347,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000, 0.9347,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000, 2.2734,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf]], device='cuda:2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bw_logprobs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf7ddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1319, -2.3026, -2.3026, -2.3026, -2.3026, -2.2589, -2.3026,  0.3275,\n",
       "        -2.2647, -2.3026], device='cuda:2')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrewards[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec9a38ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.6884,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000, 2.2829,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        ...,\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.0000,   -inf,   -inf,   -inf,   -inf,   -inf]], device='cuda:2')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2d97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f680861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000],\n",
       "         [0.0417, 0.2419],\n",
       "         [0.1684, 0.4574],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0205, 0.0151],\n",
       "         [0.0992, 0.2525],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0882, 0.1209],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0309, 0.1111]], device='cuda:2'),\n",
       " tensor([[0.0417, 0.2419],\n",
       "         [0.1268, 0.2155],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0205, 0.0151],\n",
       "         [0.0786, 0.2373],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0882, 0.1209],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0309, 0.1111],\n",
       "         [  -inf,   -inf]], device='cuda:2'),\n",
       " tensor([ 0.0000,  1.6884,  0.1319,  0.0000,  2.2829, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026], device='cuda:2'),\n",
       " tensor([[0.0417, 0.2419],\n",
       "         [0.1684, 0.4574],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0205, 0.0151],\n",
       "         [0.0992, 0.2525],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0882, 0.1209],\n",
       "         [  -inf,   -inf],\n",
       "         [0.0309, 0.1111],\n",
       "         [  -inf,   -inf]], device='cuda:2'),\n",
       " tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1.], device='cuda:2'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states[:10],  all_actions[:10], all_rewards[:10], all_next_states[:10], all_dones[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64ce3d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000],\n",
       "         [0.0417, 0.2419],\n",
       "         [0.1684, 0.4574],\n",
       "         ...,\n",
       "         [0.1730, 0.0357],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0156, 0.0259]], device='cuda:2'),\n",
       " tensor([[0.0417, 0.2419],\n",
       "         [0.1268, 0.2155],\n",
       "         [  -inf,   -inf],\n",
       "         ...,\n",
       "         [  -inf,   -inf],\n",
       "         [0.0156, 0.0259],\n",
       "         [  -inf,   -inf]], device='cuda:2'),\n",
       " tensor([ 0.0000,  1.6884,  0.1319,  0.0000,  2.2829, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  1.7183,  0.9347, -2.2589,\n",
       "          0.0000, -2.3026,  0.0000,  0.9347,  0.3275,  0.0000,  2.2734, -2.2647,\n",
       "          0.0000, -2.3026,  0.0000,  2.0349, -2.2881,  0.0000, -2.3026,  0.0000,\n",
       "          1.5620,  1.4669,  0.9347, -2.2545,  0.0000, -2.3026,  0.0000,  1.3853,\n",
       "          0.7301,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          2.5851, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  1.5966,\n",
       "          0.9347, -1.8827,  0.0000,  1.8339,  1.7513, -0.4252,  0.0000,  0.9347,\n",
       "          0.9347, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000,  2.0329,  0.9347,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  2.4888,  0.9347,\n",
       "          0.9347,  0.9347,  0.9347, -2.3026,  0.0000,  2.1253,  0.9347,  0.9347,\n",
       "         -2.3026,  0.0000,  0.9347,  0.3528,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  1.9026,  0.9347, -1.8810,  0.0000, -2.3026,\n",
       "          0.0000,  2.9284,  0.9347,  0.9347,  0.9347, -0.2044,  0.0000,  2.4106,\n",
       "         -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          2.9108,  1.2145,  0.3115,  0.0000,  2.6179,  0.9347,  0.9347, -2.3026,\n",
       "          0.0000,  3.9407, -2.3026,  0.0000, -2.3026,  0.0000,  2.9547, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  1.5418,  0.9347, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  0.9347, -0.2650,  0.0000,  2.6121, -2.3024,\n",
       "          0.0000,  1.6711,  1.0819,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000,\n",
       "          1.6473, -0.2821,  0.0000,  0.9347,  0.0281,  0.0000, -2.3026,  0.0000,\n",
       "          1.6731,  0.9347, -2.3026,  0.0000,  2.2319,  0.9347,  0.9347,  0.9347,\n",
       "          0.4978,  0.0000,  1.4731,  0.9347,  0.9347, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000,  0.9347,  0.9347, -2.3026,  0.0000,  3.5839,  0.9347,  0.4710,\n",
       "          0.0000,  0.9347,  0.5694,  0.0000,  1.9865,  0.9347, -2.0672,  0.0000,\n",
       "          0.9347,  0.9347, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  2.6630,  1.2999,  0.9347, -2.2314,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  1.4861,  0.9347,  0.9347, -2.2987,  0.0000,\n",
       "          2.2155, -2.2562,  0.0000, -2.3026,  0.0000,  1.4074,  0.9347,  0.9347,\n",
       "          0.9347, -2.3012,  0.0000,  1.1033, -0.4153,  0.0000,  1.6098,  1.5310,\n",
       "          0.9347,  0.9347,  0.9347, -2.3026,  0.0000,  1.4847,  0.9347, -2.3026,\n",
       "          0.0000,  1.4775, -1.1727,  0.0000, -2.3026,  0.0000,  3.0517,  2.5223,\n",
       "         -2.2968,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  3.3493, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  2.4059,  0.9347,  0.9347,  0.9347,  0.9347,\n",
       "         -2.3026,  0.0000,  2.1927, -2.2737,  0.0000,  3.1959,  2.0300,  1.5411,\n",
       "         -2.3026,  0.0000,  0.9347,  0.6955,  0.0000,  1.9268, -2.2226,  0.0000,\n",
       "         -2.3026,  0.0000,  0.9347,  0.9347, -2.3026,  0.0000,  0.9347,  0.6801,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  1.9541,  0.9347, -2.0019,\n",
       "          0.0000,  1.5565,  0.9347, -1.2756,  0.0000, -2.3026,  0.0000,  1.5171,\n",
       "          0.9347, -1.4326,  0.0000,  3.7835, -2.3026,  0.0000,  0.9347,  0.3569,\n",
       "          0.0000, -2.3026,  0.0000,  1.6627,  0.9347,  0.9347,  0.9347,  0.9347,\n",
       "         -2.3026,  0.0000,  1.7066, -2.0563,  0.0000,  1.9973,  0.9347,  0.9347,\n",
       "          0.9347,  0.9347, -2.3026,  0.0000,  1.9776, -2.2899,  0.0000, -2.3026,\n",
       "          0.0000,  1.3892,  0.9347, -2.3026,  0.0000,  0.9347,  0.9347, -2.0985,\n",
       "          0.0000, -2.3026,  0.0000,  1.1627,  0.9347, -2.3026,  0.0000,  1.4769,\n",
       "          0.9347,  0.9347, -1.0420,  0.0000, -2.3026,  0.0000,  1.1344, -0.9696,\n",
       "          0.0000,  1.3362,  0.9347, -2.2779,  0.0000,  1.2228, -0.5578,  0.0000,\n",
       "         -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  2.2076, -2.3007,  0.0000,  1.9762,  0.9347, -2.2976,\n",
       "          0.0000,  2.1201,  1.9590,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000,\n",
       "          1.7408, -1.3867,  0.0000,  1.4797,  0.9347, -2.2723,  0.0000, -2.3026,\n",
       "          0.0000,  1.9539,  0.9347,  0.9347, -0.8625,  0.0000,  2.3051, -2.2914,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000,  1.5610,  0.9347,  0.9347, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  3.4081,  0.9347,  0.2638,  0.0000, -2.3026,  0.0000,\n",
       "          0.9347,  0.2373,  0.0000,  2.8419, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  0.9347,  0.9347,  0.9347,  0.9347, -2.2705,  0.0000,\n",
       "          4.6781,  0.9347,  0.9347, -2.3026,  0.0000,  2.7470,  0.9347,  0.9347,\n",
       "         -2.3026,  0.0000,  1.9682, -1.7307,  0.0000,  1.7575, -1.8141,  0.0000,\n",
       "         -2.3026,  0.0000,  2.5459,  1.9578,  1.9553, -2.3022,  0.0000,  2.0202,\n",
       "         -1.8788,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          1.1757,  0.6546,  0.0000, -2.3026,  0.0000,  2.2773, -2.2860,  0.0000,\n",
       "         -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          1.1972,  0.9347, -2.3026,  0.0000,  0.9347,  0.9347,  0.9347,  0.5832,\n",
       "          0.0000,  2.2448,  0.9937, -0.4431,  0.0000, -2.3026,  0.0000,  2.4233,\n",
       "         -2.3026,  0.0000,  1.8223,  0.9347, -2.1977,  0.0000, -2.3026,  0.0000,\n",
       "          2.3409,  0.9347,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  0.9347, -0.1982,  0.0000,\n",
       "         -2.3026,  0.0000,  0.9347,  0.9347, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  2.0598, -2.2990,  0.0000,  4.6297,  1.2422,  0.9347,\n",
       "          0.2726,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  0.9347,  0.9347,\n",
       "          0.9347, -0.6442,  0.0000,  2.8207, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          3.0150,  2.3175,  0.9347, -1.7686,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000,  2.8562, -2.3025,  0.0000, -2.3026,  0.0000,  2.3610, -2.3025,\n",
       "          0.0000, -2.3026,  0.0000,  3.5068, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "          1.7041,  0.9347,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000,  3.6380,\n",
       "          1.2086,  0.9347, -2.3026,  0.0000,  2.2980, -2.3022,  0.0000,  3.7452,\n",
       "         -2.3025,  0.0000, -2.3026,  0.0000,  1.1998,  0.6536,  0.0000, -2.3026,\n",
       "          0.0000,  0.9347,  0.9347,  0.9347, -2.3026,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000,  1.3682,  0.9347, -2.3026,  0.0000,  2.6050, -2.3026,\n",
       "          0.0000,  2.9313, -2.3026,  0.0000,  0.9347,  0.9347, -2.3026,  0.0000,\n",
       "          1.9215,  0.9347,  0.9347,  0.9347, -2.2954,  0.0000,  2.7012, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  0.9347,  0.0163,  0.0000,  3.2049, -2.3026,\n",
       "          0.0000,  1.3141,  0.9347, -2.3008,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000,  0.9347,\n",
       "         -1.0419,  0.0000, -2.3026,  0.0000,  1.0217,  0.6636,  0.0000, -2.3026,\n",
       "          0.0000,  1.7110, -2.2642,  0.0000,  2.0801, -2.3025,  0.0000,  0.9347,\n",
       "          0.7058,  0.0000,  1.7219,  0.9347,  0.9347,  0.9347, -2.2466,  0.0000,\n",
       "          0.9347,  0.6127,  0.0000, -2.3026,  0.0000, -2.3026,  0.0000, -2.3026,\n",
       "          0.0000, -2.3026,  0.0000,  3.2844,  0.9347,  0.0153,  0.0000,  1.5759,\n",
       "          0.1433,  0.0000,  2.2297,  0.9347,  0.9347, -0.4362,  0.0000, -2.3026,\n",
       "          0.0000,  1.1421,  0.9347, -2.3026,  0.0000,  1.3053,  0.9347, -2.3026,\n",
       "          0.0000,  1.0545,  0.9347, -2.3026,  0.0000,  3.7607, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000, -2.3026,  0.0000,  1.9343,  1.1617,  0.9347,  0.9347,\n",
       "         -2.3026,  0.0000,  2.4176,  1.2641,  0.4265,  0.0000, -2.3026,  0.0000,\n",
       "         -2.3026,  0.0000, -2.3026], device='cuda:2'),\n",
       " tensor([[0.0417, 0.2419],\n",
       "         [0.1684, 0.4574],\n",
       "         [  -inf,   -inf],\n",
       "         ...,\n",
       "         [  -inf,   -inf],\n",
       "         [0.0156, 0.0259],\n",
       "         [  -inf,   -inf]], device='cuda:2'),\n",
       " tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "         1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.], device='cuda:2'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states, all_actions, all_rewards, all_next_states, all_dones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec2e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CGFN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
